逻辑回归是通过逻辑函数（sigmoid函数）将线性回归的输出映射到0和1之间，从而预测某个事件发生的概率
<img width="1502" height="638" alt="image" src="https://github.com/user-attachments/assets/06b31dd3-9189-4dde-b1f5-df7b98032bbf" />

<img width="1356" height="364" alt="image" src="https://github.com/user-attachments/assets/a6b19330-c2cb-4d8b-af72-4f6f21ba68cb" />

<img width="1336" height="442" alt="image" src="https://github.com/user-attachments/assets/a6c04341-ccc1-4f1a-be81-6208976d2f4b" />

和线性回归一样，逻辑回归也是通过梯度下降法来优化损失函数，求解w和b.


```python
model=LogisticRegression()
model.fit(X_train,y_train)
y_pred=model.predict(X_test)
accuracy=accuracy_score(y_test,y_pred)

```

TP(True Positive)
真正是1，预测也是1

FP(False Positive)
真正是0，预测是1  （误报）

FN（false negative)
真正是1，预测是0

TB(TRUE Negative) 
真实是0，预测是0




precision (精确率）
<img width="446" height="120" alt="image" src="https://github.com/user-attachments/assets/f4506515-2dd6-44c3-8881-58b17c4e9b4c" />
预测为1的样本中，有多少是真的1

recall(召回率）
<img width="369" height="144" alt="image" src="https://github.com/user-attachments/assets/0b61eff5-7e8e-4dc3-b276-cc785e584221" />
真实为1的样本中，有多少被找出来

F1 score  精确率和召回率的综合分
<img width="633" height="164" alt="image" src="https://github.com/user-attachments/assets/c0a7aaaf-351f-4e37-8476-96d45eb7e39d" />
对比

如果情况 A：precision=1.0，recall=0.0
你一个都没抓到（TP=0），那 F1 就是 0（完全没用）。

情况 B：precision=0.5，recall=0.5
F1 也是 0.5（中等）。

情况 C：precision=0.9，recall=0.1
看着 precision 0.9 很牛，但 recall 太差，F1 会很低（接近 0.18 左右）。
👉 这就是 F1 “惩罚短板”。



precision 很高，recall很低
就是预测很准，但是很多漏掉了

precision 很低，recall很高
几乎所有真正的1都抓到了，但是抓到了很多不该抓的








回归模型评估
